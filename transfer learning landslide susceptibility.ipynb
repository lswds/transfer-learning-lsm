{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4bc09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn import svm\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be04e195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe0a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ndatas_df=pd.read_csv(r'D:\\\\nonlandslide.csv')\n",
    "\n",
    "pdatas_df=pd.read_csv(r'D:\\\\landslide.csv',encoding='ISO-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3650c5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndatacqx['label']=0\n",
    "# pdatacqx['label']=1\n",
    "\n",
    "ndatas_df['label']=0\n",
    "\n",
    "pdatas_df['label']=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de8b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuf(i,n):\n",
    "    i=shuffle(i[['Lithology',\n",
    "       'Distance_From_Faults', 'distance_from_water', 'Distance_From_Road',\n",
    "       'SWI', 'RDLS', 'Slope', 'Aspect', 'Profile_Curvature',\n",
    "       'Plane_Curvature', 'Elevation', 'ndviwithcq', 'Soil_Type', 'Landuse',\n",
    "       'Population', 'Aridity', 'GDP', 'IM', 'Annually_Mean_Precipitation',\n",
    "       'Annually_Mean_Temperature','label']],random_state=67).dropna().reset_index().drop(columns=['index'])[:len(n)]\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb506bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndatas_df_new=shuf(ndatas_df,pdatas_df)\n",
    "pdatas_df_new=shuf(pdatas_df,ndatas_df_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ff6c42",
   "metadata": {},
   "source": [
    "# Source domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be257423",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df=ndatas_df_new.append(pdatas_df_new)\n",
    "data_df=shuffle(data_df).reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30034725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "def cosine_decay_with_warmup(global_step,\n",
    "                             learning_rate_base,\n",
    "                             total_steps,\n",
    "                             warmup_learning_rate=0.0,\n",
    "                             warmup_steps=0,\n",
    "                             hold_base_rate_steps=0):\n",
    "\n",
    "    if total_steps < warmup_steps:\n",
    "        raise ValueError('total_steps must be larger or equal to '\n",
    "                         'warmup_steps.')\n",
    "  \n",
    "    learning_rate = 0.5 * learning_rate_base * (1 + np.cos(np.pi *\n",
    "        (global_step - warmup_steps - hold_base_rate_steps) / float(total_steps - warmup_steps - hold_base_rate_steps)))\n",
    "\n",
    "    if hold_base_rate_steps > 0:\n",
    "        learning_rate = np.where(global_step > warmup_steps + hold_base_rate_steps,\n",
    "                                 learning_rate, learning_rate_base)\n",
    "    if warmup_steps > 0:\n",
    "        if learning_rate_base < warmup_learning_rate:\n",
    "            raise ValueError('learning_rate_base must be larger or equal to '\n",
    "                             'warmup_learning_rate.')\n",
    "\n",
    "        slope = (learning_rate_base - warmup_learning_rate) / warmup_steps\n",
    "        warmup_rate = slope * global_step + warmup_learning_rate\n",
    "\n",
    "        learning_rate = np.where(global_step < warmup_steps, warmup_rate,\n",
    "                                 learning_rate)\n",
    "    return np.where(global_step > total_steps, 0.0, learning_rate)\n",
    "class WarmUpCosineDecayScheduler(keras.callbacks.Callback):\n",
    "  \n",
    "    def __init__(self,\n",
    "                 learning_rate_base,\n",
    "                 total_steps,\n",
    "                 global_step_init=0,\n",
    "                 warmup_learning_rate=0.0,\n",
    "                 warmup_steps=0,\n",
    "                 hold_base_rate_steps=0,\n",
    "                 verbose=0):\n",
    "        super(WarmUpCosineDecayScheduler, self).__init__()\n",
    "        self.learning_rate_base = learning_rate_base\n",
    "        self.total_steps = total_steps\n",
    "        self.global_step = global_step_init\n",
    "        self.warmup_learning_rate = warmup_learning_rate\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.hold_base_rate_steps = hold_base_rate_steps\n",
    "        self.verbose = verbose\n",
    " \n",
    "        self.learning_rates = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.global_step = self.global_step + 1\n",
    "        lr = K.get_value(self.model.optimizer.lr)\n",
    "        self.learning_rates.append(lr)\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        lr = cosine_decay_with_warmup(global_step=self.global_step,\n",
    "                                      learning_rate_base=self.learning_rate_base,\n",
    "                                      total_steps=self.total_steps,                                      warmup_learning_rate=self.warmup_learning_rate,\n",
    "                                      warmup_steps=self.warmup_steps,                                    hold_base_rate_steps=self.hold_base_rate_steps)\n",
    "        K.set_value(self.model.optimizer.lr, lr)\n",
    "        if self.verbose > 0:\n",
    "            print('\\nBatch %05d: setting learning '\n",
    "                  'rate to %s.' % (self.global_step + 1, lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74981a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data_df.iloc[:,:-1]\n",
    "label=data_df.iloc[:,-1]\n",
    "feat_labels=data_df.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225432cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(data,label,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bece3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=Xtrain.mean(axis=0)\n",
    "std=Xtrain.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9c68f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain=(Xtrain-mean)/std\n",
    "Xtest=(Xtest-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4199eb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtraincq=(Xtraincq-cqmean)/cqstd\n",
    "# Xtestcq=(Xtestcq-cqmean)/cqstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04efabaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain=np.expand_dims(Xtrain,-1)\n",
    "Xtest=np.expand_dims(Xtest,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982857de",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras=tf.keras\n",
    "layers=tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e306725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.Sequential()\n",
    "\n",
    "model.add(layers.Conv1D(64,3,activation='relu',padding='same'))\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "model.add(layers.Dropout(0.1))\n",
    "\n",
    "model.add(layers.Conv1D(128,3,activation='relu',padding='same'))\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "model.add(layers.Dropout(0.1))\n",
    "\n",
    "model.add(layers.Conv1D(256,3,activation='relu',padding='same'))\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "model.add(layers.Dropout(0.1))\n",
    "\n",
    "model.add(layers.Conv1D(512,3,activation='relu',padding='same'))\n",
    "model.add(layers.MaxPooling1D(2))\n",
    "model.add(layers.Dropout(0.1))\n",
    "\n",
    "model.add(layers.Bidirectional(layers.LSTM(256,return_sequences=True)))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Bidirectional(layers.LSTM(128,return_sequences=True)))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "\n",
    "\n",
    "model.add(layers.Dense(128))\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51e3985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #8087\n",
    "\n",
    "# model=keras.Sequential()\n",
    "# model.add(layers.Conv1D(32,1,input_shape=(Xtrain.shape[1:]),activation='relu',padding='same'))\n",
    "# model.add(layers.Conv1D(32,3,input_shape=(Xtrain.shape[1:]),activation='relu',padding='same'))\n",
    "# model.add(layers.Conv1D(32,5,input_shape=(Xtrain.shape[1:]),activation='relu',padding='same'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.MaxPooling1D(2))\n",
    "# model.add(layers.Dropout(0.3))\n",
    "\n",
    "# model.add(layers.Conv1D(64,5,activation='relu',padding='same'))\n",
    "# model.add(layers.Conv1D(64,5,activation='relu',padding='same'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.MaxPooling1D(2))\n",
    "# model.add(layers.Dropout(0.5))\n",
    "\n",
    "# model.add(layers.Conv1D(128,5,activation='relu',padding='same'))\n",
    "# model.add(layers.Conv1D(128,5,activation='relu',padding='same'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.MaxPooling1D(2))\n",
    "# model.add(layers.Dropout(0.6))\n",
    "\n",
    "\n",
    "# model.add(layers.Conv1D(256,3,activation='relu',padding='same'))\n",
    "# model.add(layers.Conv1D(256,3,activation='relu',padding='same'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.MaxPooling1D(2))\n",
    "# model.add(layers.Dropout(0.6))\n",
    "\n",
    "# model.add(layers.Conv1D(512,1,activation='relu',padding='same'))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Dropout(0.5))\n",
    "\n",
    "# model.add(layers.Bidirectional(layers.LSTM(256,return_sequences=True)))\n",
    "# model.add(layers.Dropout(0.5))\n",
    "\n",
    "# model.add(layers.Bidirectional(layers.LSTM(128,return_sequences=True)))\n",
    "# model.add(layers.Dropout(0.5))\n",
    "\n",
    "# model.add(layers.Bidirectional(layers.LSTM(128)))\n",
    "# model.add(layers.Dropout(0.5))\n",
    "\n",
    "\n",
    "# model.add(layers.Dense(64))\n",
    "# model.add(layers.Dense(32))\n",
    "# model.add(layers.Dense(16))\n",
    "# model.add(layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c5c949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b65b1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "             loss='binary_crossentropy',\n",
    "             metrics='AUC',\n",
    "             \n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590a122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01a967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_count = Xtrain.shape[0]\n",
    "# Total epochs to train.\n",
    "epochs = 10\n",
    "# Number of warmup epochs.\n",
    "warmup_epoch = 5\n",
    "# Training batch size, set small value here for demonstration purpose.\n",
    "batch_size = 512\n",
    "# Base learning rate after warmup.\n",
    "learning_rate_base = 0.001\n",
    "\n",
    "total_steps = int(epochs * sample_count / batch_size)\n",
    "# Compute the number of warmup batches.\n",
    "warmup_steps = int(warmup_epoch * sample_count / batch_size)\n",
    "\n",
    "\n",
    "\n",
    "# Compute the number of warmup batches.\n",
    "warmup_batches = warmup_epoch * sample_count / batch_size\n",
    "\n",
    "# Create the Learning rate scheduler.\n",
    "warm_up_lr = WarmUpCosineDecayScheduler(learning_rate_base=learning_rate_base,\n",
    "                                            total_steps=total_steps,\n",
    "                                            warmup_learning_rate=4e-06,\n",
    "                                            warmup_steps=warmup_steps,\n",
    "                                            hold_base_rate_steps=5,\n",
    "                                            )\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(warm_up_lr.learning_rates)\n",
    "# plt.xlabel('Step', fontsize=20)\n",
    "# plt.ylabel('lr', fontsize=20)\n",
    "# plt.axis([0, total_steps, 0, learning_rate_base*1.1])\n",
    "# plt.xticks(np.arange(0, epochs, 1))\n",
    "# plt.grid()\n",
    "# plt.title('Cosine decay with warmup', fontsize=20)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec7b92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(Xtrain, Ytrain, epochs=100, batch_size=512, callbacks=[warm_up_lr],validation_data=(Xtest,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ca3042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(warm_up_lr.learning_rates)\n",
    "plt.xlabel('Step', fontsize=20)\n",
    "plt.ylabel('lr', fontsize=20)\n",
    "plt.axis([0, total_steps, 0, learning_rate_base*1.1])\n",
    "plt.xticks(np.arange(0, epochs, 1))\n",
    "plt.grid()\n",
    "plt.title('Cosine decay with warmup', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55d98ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(r'D:Source_Model.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca54a658",
   "metadata": {},
   "source": [
    "# Target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78fa59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndatacqd=pd.read_csv(r'D:\\\\Target\\\\Nonlandslide.csv')\n",
    "pdatacqd=pd.read_csv(r'D:\\\\Target\\\\Landslide.csv',encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2f9a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndatacqd['label']=0\n",
    "pdatacqd['label']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6980cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndatacqd=ndatacqd.rename(columns={'Distance_from_Faultscq':'Distance_From_Faults'})\n",
    "pdatacqd=pdatacqd.rename(columns={'Distance_from_Faultscq':'Distance_From_Faults'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1f557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ndata_cqd_new=shuf(ndatacqd,pdatacqd)\n",
    "pdata_cqd_new=shuf(pdatacqd,ndata_cqd_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe0a61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_cqd=ndata_cqd_new.append(pdata_cqd_new)\n",
    "data_cqd=shuffle(data_cqd).reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da8713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cqddata=data_cqd.iloc[:,:-1]\n",
    "cqdlabel=data_cqd.iloc[:,-1]\n",
    "cqdfeat_labels=data_cqd.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824b5722",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtraincqd, Xtestcqd, Ytraincqd, Ytestcqd = train_test_split(cqddata,cqdlabel,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c82ccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cqdmean=Xtraincqd.mean(axis=0)\n",
    "cqdstd=Xtraincqd.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb3014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtraincqd=(Xtraincqd-mean[:len(Xtraincqd)])/std[:len(Xtraincqd)]\n",
    "# Xtestcqd=(Xtestcqd-mean[:len(Xtraincqd)])/std[:len(Xtraincqd)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa64dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtraincqd=(Xtraincqd-cqdmean)/cqdstd\n",
    "Xtestcqd=(Xtestcqd-cqdmean)/cqdstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598516f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtraincqd=np.expand_dims(Xtraincqd,-1)\n",
    "Xtestcqd=np.expand_dims(Xtestcqd,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c0ea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv=tf.keras.models.load_model(r'D:Source_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdc37d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    conv.layers[i].trainable=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f208e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.Sequential(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449f4d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "             loss='binary_crossentropy',\n",
    "             metrics='AUC',        \n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f37634",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_count = Xtraincqd.shape[0]\n",
    "# Total epochs to train.\n",
    "epochs = 100\n",
    "# Number of warmup epochs.\n",
    "warmup_epoch = 5\n",
    "# Training batch size, set small value here for demonstration purpose.\n",
    "batch_size = 512\n",
    "# Base learning rate after warmup.\n",
    "learning_rate_base = 0.001\n",
    "\n",
    "total_steps = int(epochs * sample_count / batch_size)\n",
    "# Compute the number of warmup batches.\n",
    "warmup_steps = int(warmup_epoch * sample_count / batch_size)\n",
    "\n",
    "\n",
    "\n",
    "# Compute the number of warmup batches.\n",
    "warmup_batches = warmup_epoch * sample_count / batch_size\n",
    "\n",
    "# Create the Learning rate scheduler.\n",
    "warm_up_lr_target = WarmUpCosineDecayScheduler(learning_rate_base=learning_rate_base,\n",
    "                                            total_steps=total_steps,\n",
    "                                            warmup_learning_rate=4e-06,\n",
    "                                            warmup_steps=warmup_steps,\n",
    "                                            hold_base_rate_steps=5,\n",
    "                                            )\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(warm_up_lr.learning_rates)\n",
    "# plt.xlabel('Step', fontsize=20)\n",
    "# plt.ylabel('lr', fontsize=20)\n",
    "# plt.axis([0, total_steps, 0, learning_rate_base*1.1])\n",
    "# plt.xticks(np.arange(0, epochs, 1))\n",
    "# plt.grid()\n",
    "# plt.title('Cosine decay with warmup', fontsize=20)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbb8e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_target=model.fit(Xtraincqd, Ytraincqd, epochs=100, batch_size=512,callbacks=[warm_up_lr_target],validation_data=(Xtestcqd,Ytestcqd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d6ba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cq_=pd.read_csv(r'D:\\\\cqfishnet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f378a4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cq_=cq_.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97914f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "cq_data=cq_[['Lithology',\n",
    "       'Distance_From_Faults', 'distance_from_water', 'Distance_From_Road',\n",
    "       'SWI', 'RDLS', 'Slope', 'Aspect', 'Profile_Curvature',\n",
    "       'Plane_Curvature', 'Elevation', 'ndviwithcq', 'Soil_Type', 'Landuse',\n",
    "       'Population', 'Aridity', 'GDP', 'IM', 'Annually_Mean_Precipitation',\n",
    "       'Annually_Mean_Temperature']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0321cb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "cq_mean=cq_data.mean(axis=0)\n",
    "cq_std=cq_data.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54011fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cq_data=(cq_data-cq_mean)/cq_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f9b860",
   "metadata": {},
   "outputs": [],
   "source": [
    "cq_data=np.expand_dims(cq_data,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21591f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "susceptibility5_=model.predict(cq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245f481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "susceptibility5_df_=pd.DataFrame(susceptibility5_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8efaf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "cq_['susceptibility5_dl']=susceptibility5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70611a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "susceptibility5_df_dl=cq_[['OBJECTID','susceptibility5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d3b9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "susceptibility5_df_dl.to_csv(r'D:\\\\susceptibility5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69acb617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8862da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
